{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import randint\n",
    "from time import clock\n",
    "\n",
    "import utils.movie_plotutils as plu\n",
    "import utils.readMov as rmov\n",
    "#import utils.dirutils as diru\n",
    "\n",
    "#code to reload\n",
    "import imp\n",
    "imp.reload(plu)\n",
    "imp.reload(rmov)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs = {'dpi' : 200} #plotting pretty\n",
    "\n",
    "#code to limit number of CPUs\n",
    "\n",
    "#maxcpus = 2\n",
    "#session_conf = tf.ConfigProto(\n",
    "#     intra_op_parallelism_threads=maxcpus,\n",
    "#     inter_op_parallelism_threads=maxcpus, allow_soft_placement=True, device_count = {'CPU': maxcpus})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random.seed(1234)\n",
    "#tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class aec_model(object):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "      params = self.add_params(params)\n",
    "      self.params = params\n",
    "      self.make_dirs()\n",
    "      self.graph = self.make_graph()\n",
    "    \n",
    "    def add_params(self, params):  \n",
    "        params['compression'] = params['imxlen']*params['imylen']/params['nneurons']\n",
    "        params['savefolder'] = str('./output/movie_output/actfun_'+ params['model_type']+\n",
    "                                   '_hiddenneurons_'+ str(params['nneurons'])+\n",
    "                                   '_noisein_'+ str(params['noise_x'])+\n",
    "                                   '_noiseout_'+ str(params['noise_r'])+\n",
    "                                   '_lambda_'+ str(params['lambd'])+'/')\n",
    "        return(params)\n",
    "        \n",
    "    def make_dirs(self):\n",
    "        if not os.path.exists(self.params['savefolder']):\n",
    "            os.makedirs(self.params['savefolder'])\n",
    "        \n",
    "    def make_graph(self):\n",
    "    \n",
    "        print('Compressing by',self.params['compression'],'for a total of',self.params['nneurons'],'neurons')\n",
    "\n",
    "        #setup our graph\n",
    "        #tf.reset_default_graph()\n",
    "        mygraph = tf.Graph()\n",
    "        with mygraph.as_default():\n",
    "\n",
    "            #input images\n",
    "            with tf.name_scope('input'):\n",
    "                self.x = tf.placeholder(tf.float32, shape=[self.params[\"batchsize\"], \n",
    "                                                           self.params[\"time_patchsize\"],self.params[\"imxlen\"],self.params[\"imylen\"], 1])\n",
    "\n",
    "            #activation function type\n",
    "            with tf.name_scope('activation_function'):\n",
    "                self.act_fun = self.params['model_type']\n",
    "\n",
    "            #noises\n",
    "            with tf.name_scope('noises'):\n",
    "                self.noisexsigma = self.params['noise_x']\n",
    "                self.noisersigma = self.params['noise_r']\n",
    "\n",
    "            #function to add noise\n",
    "            with tf.name_scope(\"add_noise\"):\n",
    "                def add_noise(input_layer, std):\n",
    "                    noise = tf.random_normal(shape=tf.shape(input_layer), mean=0.0, stddev=std, dtype=tf.float32) \n",
    "                    return tf.add(input_layer,noise)\n",
    "\n",
    "            #weights\n",
    "            with tf.variable_scope(\"weights\"):\n",
    "                \n",
    "               \n",
    "    \n",
    "                weights_kernel = tf.random_normal([self.params['frames_per_channel'],self.params['imxlen'],self.params['imylen'], 1,\n",
    "                                                         self.params['nneurons']],\n",
    "                                                        dtype=tf.float32,stddev=0.1)\n",
    "                \n",
    "                self.win = tf.get_variable('weights_in',initializer=weights_kernel)\n",
    "                self.wout = tf.get_variable('weights_out',initializer=weights_kernel)\n",
    "                #self.wout = tf.get_variable('weights_out',initializer=tf.transpose(weights_kernel))\n",
    "\n",
    "            #bias\n",
    "            with tf.variable_scope(\"bias\"):\n",
    "                self.bias = tf.Variable(tf.random_normal([self.params['nneurons']],dtype=tf.float32,stddev=0.1))\n",
    "\n",
    "            #lambda\n",
    "            with tf.name_scope('lambda'):\n",
    "                self.lambd = self.params['lambd']\n",
    "\n",
    "            #learning_rate\n",
    "            with tf.name_scope('learning_rate'):\n",
    "                self.learning_rate = self.params['learning_rate']\n",
    "\n",
    "            #nonlienarities\n",
    "            with tf.name_scope(\"nonlienarities\"):\n",
    "                #define nonlinearities\n",
    "                def tanh_fun(arg):\n",
    "                    return tf.nn.tanh(arg) \n",
    "                def sigmoid_fun(arg):\n",
    "                    return tf.nn.sigmoid(arg) \n",
    "                def relu_fun(arg):\n",
    "                    return tf.nn.relu(arg) \n",
    "                def no_fun(arg):\n",
    "                    return arg\n",
    "\n",
    "            #encoding part of model\n",
    "            with tf.name_scope(\"encoding\"):\n",
    "                #calculate input\n",
    "                \n",
    "                linearin = tf.add(tf.nn.conv3d(add_noise(self.x,self.params['noise_x']), self.win, strides=[1,1,self.params['imxlen'],self.params['imylen'],1], padding='SAME'),self.bias) #Convolution over time, add noise to input, and multiply by weights\n",
    "                #linearin = tf.add(tf.matmul(add_noise(self.x,self.params['noise_x']),self.win),self.bias) #add noise to input, and multiply by weights\n",
    "                self.yin_no_noise = tf.case({tf.equal(self.act_fun,'tanh'): (lambda: tanh_fun(linearin)),\n",
    "                               tf.equal(self.act_fun,'sigmoid'): (lambda: sigmoid_fun(linearin)),\n",
    "                               tf.equal(self.act_fun,'relu'): (lambda: relu_fun(linearin))},\n",
    "                               default=(lambda: no_fun(linearin)),\n",
    "                               exclusive=True)\n",
    "                self.yin = add_noise(self.yin_no_noise,self.params['noise_r'])\n",
    "                \n",
    "                #self.yin = linearin\n",
    "                \n",
    "                #print(yin)\n",
    "                #self.yin = tf.case({tf.equal(self.act_fun,'tanh'): (lambda: tanh_fun(self.yin)),\n",
    "                #               tf.equal(self.act_fun,'sigmoid'): (lambda: sigmoid_fun(self.yin)),\n",
    "                #               tf.equal(self.act_fun,'relu'): (lambda: relu_fun(self.yin))},\n",
    "                #              default=(lambda: no_fun(self.yin)),\n",
    "                #              exclusive=True)\n",
    "\n",
    "            #output part of model\n",
    "            with tf.name_scope(\"decoding\"):\n",
    "                #calculate output (reconstruction)\n",
    "                \n",
    "                self.xp = tf.nn.conv3d_transpose(self.yin, self.wout, output_shape=(self.params[\"batchsize\"], self.params[\"time_patchsize\"],self.params[\"imxlen\"],self.params[\"imylen\"], 1), strides=[1,1,self.params['imxlen'],self.params['imylen'],1], padding='SAME') #Deconvolution \n",
    "                #self.xp = tf.nn.conv3d(self.yin, self.wout, output_shape=[self.params[\"batchsize\"], self.params[\"time_patchsize\"]*self.params[\"imxlen\"]*self.params[\"imylen\"],strides=[1,1,1,1,1], padding='SAME')\n",
    "                \n",
    "                #self.xp = tf.matmul(self.yin,self.wout) #add noise to inner layer, and multiply by weight transpose\n",
    "                #self.xp = tf.case({tf.equal(self.act_fun,'tanh'): (lambda: tanh_fun(linearout)),\n",
    "                #                    tf.equal(self.act_fun,'sigmoid'): (lambda: sigmoid_fun(linearout)),\n",
    "                #                    tf.equal(self.act_fun,'relu'): (lambda: relu_fun(linearout))},\n",
    "                #                    default=(lambda: no_fun(linearout)),\n",
    "                #                    exclusive=True, name='output_nonlienarity')\n",
    "             \n",
    "\n",
    "            #calculate cost\n",
    "            with tf.name_scope(\"cost_function\"):\n",
    "                self.cost = tf.sqrt(tf.reduce_mean(tf.square(self.x-self.xp))) + tf.reduce_mean(tf.abs(self.yin_no_noise*self.lambd))\n",
    "                self.cost_reconstruct = tf.sqrt(tf.reduce_mean(tf.square(self.x-self.xp)))\n",
    "                self.cost_metabolic = tf.reduce_mean(tf.abs(self.yin_no_noise*self.lambd))\n",
    "\n",
    "            #train our model\n",
    "            with tf.name_scope(\"training_step\"):\n",
    "                self.train_step = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
    "\n",
    "            # create a summary for our cost, im, reconstruction, & weights\n",
    "            with tf.name_scope('cost_viz'):\n",
    "                tf.summary.scalar(\"cost\", self.cost)\n",
    "\n",
    "            #with tf.name_scope('image_viz'):    \n",
    "            #    x_t = tf.reshape(self.x,(self.params['batchsize'], 0, self.params['imxlen'],self.params['imylen'],1))\n",
    "            #    tf.summary.image(\"image\", x_t, max_outputs=self.params[\"batchsize\"])\n",
    "\n",
    "            #with tf.name_scope('recon_viz'):\n",
    "            #    xp_t = tf.reshape(self.xp,(self.params['batchsize'], 0,self.params['imxlen'],self.params['imylen'],1))\n",
    "            #    print (xp_t)\n",
    "            #    tf.summary.image(\"recon\", xp_t,max_outputs=self.params[\"batchsize\"])\n",
    "#CHANGE\n",
    "            #with tf.name_scope('inweights_viz'):    \n",
    "            #    #inwin_t = tf.reshape(tf.transpose(self.win),\n",
    "            #    #inwin_t = tf.reshape(tf.transpose(self.win, perm=[3,0,1,2]), (self.params['nneurons'], self.params['imxlen'], self.params['imylen'],1))\n",
    "            #    inwin_t = tf.transpose(self.win, perm=[0,4,1,2,3])\n",
    "            #    tf.summary.image(\"inweights\", inwin_t, max_outputs=self.params['nneurons'])\n",
    "                \n",
    "            #with tf.name_scope('outweights_viz'):    \n",
    "            #    #outwin_t = tf.reshape(tf.transpose(self.wout[0], perm=[3,0,1,2]), (self.params['nneurons'], self.params['imxlen'], self.params['imylen'],1))\n",
    "            #    outwin_t = tf.transpose(self.wout, perm=[0,4,1,2,3])\n",
    "            #    tf.summary.image(\"outweights\", outwin_t, max_outputs=self.params['nneurons'])\n",
    "                      \n",
    "            #with tf.name_scope('activnonlin_viz'):\n",
    "            #    activation = tf.transpose(self.yin, perm=[0,4,1,2,3])\n",
    "            #    activation = tf.reshape(activation, (self.params[\"batchsize\"], self.params[\"time_patchsize\"], -1))  #reshape nonlinear-vector [batchsize, nneurons, time] \n",
    "            #    activ_help_temp = activation[0,0] # temporarily take only one nneuron over time\n",
    "            #    tf.summary.scalar(\"activnonlin\", activ_help_temp)     \n",
    "                \n",
    "                \n",
    "            # merge all summaries into a single \"operation\" which we can execute in a session \n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "        return(mygraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#make session and train model\n",
    "def train_model(aec):\n",
    "    session_conf = tf.ConfigProto()\n",
    "    session_conf.gpu_options.allow_growth = True\n",
    "    #tf.device(\"/gpu:0\")\n",
    "    with tf.Session(graph = aec.graph, config = session_conf) as sess:   #config = session_conf\n",
    "\n",
    "        #initialize vars\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        #summary writer for tensorboard\n",
    "        writer = tf.summary.FileWriter(aec.params['savefolder'],\n",
    "                                       graph=tf.get_default_graph())\n",
    "\n",
    "        #save evolution of system over training\n",
    "        cost_evolution = []\n",
    "        wmean_evolution = []\n",
    "\n",
    "        inweights_evolution = []\n",
    "        outweights_evolution = []\n",
    "        \n",
    "        images = []\n",
    "        recons = []\n",
    "        print('{} hidden neurons, noise_in at {}, noise_out at {}, lambda at {}'.format(aec.params['nneurons'],\n",
    "                                                                                          aec.params['noise_x'],\n",
    "                                                                                          aec.params['noise_r'],\n",
    "                                                                                          aec.params['lambd']))\n",
    "        \n",
    "        print('Training {} iterations in {} epochs... '.format(aec.params['iterations'],\n",
    "                                                                   aec.params['epochs']))\n",
    "        for epoch in range(aec.params['epochs']):\n",
    "            start = clock()\n",
    "            #print('Epoch {}: '.format(epoch+1))\n",
    "            np.random.shuffle(m)\n",
    "            #print ('Time_shuffle:', (clock()-start))\n",
    "            for ii in range(aec.params['iterations']):\n",
    "                \n",
    "                #reshape our images for feeding to dict\n",
    "                clip = np.reshape(m[ii*aec.params['batchsize']:(1+ii)*aec.params['batchsize'],:,:,:],(aec.params['batchsize'], aec.params[\"time_patchsize\"], aec.params['imxlen'],aec.params['imylen'], 1)).astype(np.float32)\n",
    "                \n",
    "                #setup params to send to dictionary\n",
    "                feeddict = {aec.x: clip}\n",
    "    #                        aec.params['model_type']: params['model_type'],\n",
    "    #                        aec.params['noise_x']: params['noise_x'],\n",
    "    #                        aec.params['noise_r']: params['noise_r'],\n",
    "    #                        aec.params['lambd']: params['lambd'],\n",
    "    #                        aec.params['learning_rate']: params['learning_rate']\n",
    "    #                        }\n",
    "\n",
    "    \n",
    "\n",
    "                #run our session\n",
    "                sess.run(aec.train_step, feed_dict=feeddict)\n",
    "                \n",
    "                #yin = sess.run(aec.yin, feed_dict=feeddict)\n",
    "                #print('yin_sum: ', np.sum(np.absolute(yin)))\n",
    "                #print('yin_mean: ', np.mean(yin))\n",
    "                \n",
    "                \n",
    "                #save evolution of params\n",
    "                objcost, inws = sess.run([aec.cost, aec.win], feed_dict=feeddict)\n",
    "                cost_evolution.append(objcost)\n",
    "                wmean_evolution.append(np.mean(np.absolute(inws)))\n",
    "\n",
    "                #save detailed parameters 10 times over the total evolution\n",
    "                if(((params['iterations']*epoch)+ii)%(int((aec.params['iterations']*aec.params['epochs'])/10))==0):\n",
    "                    #dump our params\n",
    "                    win, wout, img, recon = sess.run([aec.win, aec.wout, aec.x, aec.xp], feed_dict=feeddict)\n",
    "                    #save our weights, image, and reconstruction\n",
    "                    #inweights_evolution.append(np.reshape(np.transpose(win[0], (0,1,3,2)), (params['imxlen'], params['imylen'], params['nneurons'],1)))\n",
    "                    #outweights_evolution.append(np.reshape(np.transpose(wout[0], (0,1,3,2)), (params['imxlen'], params['imylen'], params['nneurons'],1)))\n",
    "                    inweights_evolution.append(np.transpose(win, (0,1,2,4,3)))\n",
    "                    outweights_evolution.append(np.transpose(wout, (0,1,2,4,3)))\n",
    "                    #imshape = [aec.params['batchsize'],\n",
    "                    #          aec.params['imxlen'],\n",
    "                    #          aec.params['imylen']]\n",
    "                    img_transformed = np.transpose(img, (1,4,0,2,3))\n",
    "                    recons_transformed = np.transpose(recon, (1,4,0,2,3))\n",
    "                    images.append(img_transformed[0][0])\n",
    "                    recons.append(recons_transformed[0][0])\n",
    "                    \n",
    "                    cost1_all, cost_reconstruct, cost_metabolic = sess.run([aec.cost, aec.cost_reconstruct, aec.cost_metabolic], feed_dict=feeddict)\n",
    "                    print('cost1_all: ', cost1_all)\n",
    "                    print('cost_reconstruct: ', cost_reconstruct)\n",
    "                    print('cost_metabolic: ', cost_metabolic)\n",
    "                    print('\\n')\n",
    "\n",
    "\n",
    "            end = clock()\n",
    "            print ('Time needed for one epoch: ', \"%.2f\" % (end-start),'sec')\n",
    "        #summarize final params\n",
    "        summary, objcost, inws, outws = sess.run([aec.summary_op, aec.cost, aec.win, aec.wout], feed_dict=feeddict)\n",
    "        cost_evolution.append(objcost)\n",
    "        wmean_evolution.append(np.mean(inws))\n",
    "        final_inweights = 1#transform_weight_to_image(inws, aec.params)    #aec.win\n",
    "        final_outweights = 1#transform_weight_to_image(outws, aec.params)  #aec.wout\n",
    "        #final_outweights = outws\n",
    "        #print(tf.shape(final_outweights))\n",
    "        writer.add_summary(summary,ii)\n",
    "        writer.close()\n",
    "\n",
    "    print('Done calculating!')\n",
    "    \n",
    "    return(cost_evolution,\n",
    "            wmean_evolution,\n",
    "            inweights_evolution,\n",
    "            outweights_evolution,\n",
    "            images,\n",
    "            recons,\n",
    "            final_inweights,\n",
    "            final_outweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#transform weight tensor to image format\n",
    "def transform_weight_to_image(weight_vec, params):\n",
    "    image = tf.transpose(weight_vec, perm=[1,2,4,0,3])\n",
    "    image = tf.reshape(image, (params['imxlen'], params['imylen'], params['nneurons']))#,1))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set parameters for parameter sweep\n",
    "params = {} #make a dictionary\n",
    "\n",
    "#parameters constant for all\n",
    "params[\"patchsize\"] = 10\n",
    "params[\"imxlen\"] = params[\"patchsize\"]\n",
    "params[\"imylen\"] = params[\"patchsize\"]\n",
    "params[\"time_patchsize\"] = 12\n",
    "\n",
    "params['frames_per_channel'] = 5    #number of frames that project on one channel \n",
    "\n",
    "params[\"iterations\"] = 900\n",
    "params[\"epochs\"] = 4\n",
    "\n",
    "params[\"batchsize\"] = 100\n",
    "params[\"learning_rate\"] = 0.001\n",
    "\n",
    "#params for sweeping\n",
    "nneurons = [64,100]\n",
    "#nneurons = [50]\n",
    "\n",
    "#lambdas = [1e-4]\n",
    "lambdas = [0,1e-6,1e-4, 1e-2]\n",
    "#lambdas = [0.01,0.02,0.011,]\n",
    "\n",
    "#models = ['sigmoid']\n",
    "#models = ['tanh']\n",
    "models = ['relu']#, 'sigmoid', 'tanh']\n",
    "\n",
    "\n",
    "#batchsizes = [100,1000]\n",
    "#learning_rates = [0.05,0.01,0.1]\n",
    "\n",
    "\n",
    "noise_xs_rs_pairs = [[0.,0.], [1e-1, 5], [1e-1, 2], [1e-1, 3.5], [1e-3,5e-1]]\n",
    "#noise_xs_rs_pairs = [[1e-3,5e-1]]\n",
    "#noise_xs_rs_pairs = [[0.,0.],\n",
    "#noise_xs_rs_pairs = [[1e-7,1e-5],\n",
    "#                    [1e-6,1e-4],\n",
    "#                    [1e-5,1e-3],\n",
    "#                    [1e-4,1e-2]]\n",
    "#noise_xs = [1,1e-1,1e-3,1e-5,0]\n",
    "#noise_rs = [1,1e-1,1e-3,1e-5,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = '/home/vasha/vanHaterenNaturalMovies/vid075'\n",
    "fps = 25 #approximated from http://redwood.berkeley.edu/bruno/data/vid075/README and increased by me.\n",
    "nframes = 9600\n",
    "rawframeh = 128\n",
    "rawframew = 128\n",
    "barw = 16\n",
    "framew = rawframew - barw #in pixels\n",
    "frameh = rawframeh - barw #in pixels\n",
    "\n",
    "#convert to degrees\n",
    "ppd = 6 #pixels per degree subtended on retina (estimated 10deg for 64px in dong atick 95)\n",
    "framewdeg = framew/ppd \n",
    "framehdeg = frameh/ppd\n",
    "#sampling rate\n",
    "deltawdeg = 1./ppd\n",
    "deltahdeg = 1./ppd \n",
    "deltathz = 1./fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing movie...\n",
      "(9600, 112, 112)\n",
      "making patches...\n",
      "(11, 9600, 112, 10)\n",
      "(11, 11, 9600, 10, 10)\n",
      "(800, 11, 11, 12, 10, 10)\n",
      "(96800, 10, 10, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96800, 12, 10, 10)"
      ]
     },
     "execution_count": 1129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vhimgs, params['nimages'] = imr.check_n_load_ims(params['patchsize'], params['iterations'])\n",
    "m = rmov.readMov(fpath, nframes, rawframeh, rawframew, barw, patch_edge_size=params[\"patchsize\"], time_size=params[\"time_patchsize\"], normalize_patch=False, normalize_movie=True)\n",
    "m = np.transpose(m, (0, 3, 1, 2)) #change axis to [batchsize, time_patchsize, x_patchsize, y_patchsize]\n",
    "np.random.shuffle(m)\n",
    "np.shape(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Loaded. Shape is (96800, 12, 10, 10)\n",
      "Training 90000 out of 96800 total patches.\n"
     ]
    }
   ],
   "source": [
    "#load in movie\n",
    "try:\n",
    "    m\n",
    "except NameError:\n",
    "    print(\"Loading Movie...\")\n",
    "    m = rmov.readMov(fpath, nframes, rawframeh, rawframew, barw, patch_edge_size=params[\"patchsize\"], time_size=params[\"time_patchsize\"], normalize_patch=False, normalize_movie=True)\n",
    "    m = np.transpose(m, (0, 3, 1, 2)) #change axis to [batchsize, time_patchsize, x_patchsize, y_patchsize]\n",
    "    np.random.shuffle(m)\n",
    "    #mm = m - np.mean(m,axis=(1,2)).reshape(-1,1,1)\n",
    "    \n",
    "print(\"Movie Loaded. Shape is \" + str(np.shape(m)))\n",
    "\n",
    "\n",
    "#params of clips\n",
    "imxlen = len(m[0,:,0,0])\n",
    "imylen = len(m[0,0,:,0])\n",
    "imflen = len(m[0,0,0,:])\n",
    "nimages = len(m[:,0,0,0])\n",
    "\n",
    "nimstrained = params[\"batchsize\"] * params[\"iterations\"]\n",
    "\n",
    "if(nimstrained > nimages):\n",
    "    print('ERROR! Trying to train',nimstrained,'patchess, but we only have',nimages,'patches!')\n",
    "else:\n",
    "    print('Training',nimstrained,'out of',nimages,'total patches.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nneurons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8d27f5bf2722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mneurons\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnneurons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nneurons'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlambd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nneurons' is not defined"
     ]
    }
   ],
   "source": [
    "for neurons in nneurons:\n",
    "    params['nneurons'] = neurons\n",
    "    for model_type in models:\n",
    "        params['model_type'] = model_type      \n",
    "        for lambd in lambdas:\n",
    "            params['lambd'] = lambd\n",
    "            #for nx in noise_xs:i\n",
    "                #params['noise_x'] = nx\n",
    "                #for nr in noise_rs:\n",
    "                    #params['noise_r'] = nr\n",
    "            for xs,rs in noise_xs_rs_pairs:\n",
    "                    params['noise_x'] = xs\n",
    "                    params['noise_r'] = rs\n",
    "                    #make our model\n",
    "                    aec = aec_model(params)\n",
    "                    #train it\n",
    "                    [cost_evolution,\n",
    "                     wmean_evolution,\n",
    "                     inweights_evolution,\n",
    "                     outweights_evolution,\n",
    "                     images,\n",
    "                     recons,\n",
    "                     final_inweights,\n",
    "                     final_outweights] = train_model(aec)\n",
    "\n",
    "                    plu.save_plots(aec,\n",
    "                                    cost_evolution,\n",
    "                                    wmean_evolution,\n",
    "                                    inweights_evolution,\n",
    "                                    outweights_evolution,\n",
    "                                    images,\n",
    "                                    recons,\n",
    "                                    final_inweights,\n",
    "                                    final_outweights)\n",
    "                    print('Done saving!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## show an example image\n",
    "plt.imshow(m[274,1,:,:],cmap='gray',interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
