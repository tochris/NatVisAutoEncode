{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{in} = F_{act}((Im+n_{in} W_{in}) + bias) $$\n",
    "$$ Im^* = F_{act}(y_{in} W_{in}^T) + n_{out} $$\n",
    "\n",
    "$$ Cost = \\sqrt{\\langle|Im-Im^*|\\rangle} + \\lambda \\langle r \\rangle $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.plotutils as plu\n",
    "import utils.imreadin as imr\n",
    "#import utils.dirutils as diru\n",
    "\n",
    "#code to reload\n",
    "import imp\n",
    "imp.reload(plu)\n",
    "\n",
    "#code to limit number of CPUs\n",
    "maxcpus = 1\n",
    "#%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs = {'dpi' : 200} #plotting pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class aec_model(object):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "      params = self.add_params(params)\n",
    "      self.params = params\n",
    "      self.make_dirs()\n",
    "      self.graph = self.make_graph()\n",
    "    \n",
    "    def add_params(self, params):  \n",
    "        params['compression'] = params['imxlen']*params['imylen']/params['nneurons']\n",
    "        params['savefolder'] = str('./output/image_output/' + \n",
    "                                   '_nonlin1_' + str(params['nonlin1'])+ \n",
    "                                   '_nonlin2_' + str(params['nonlin2'])+\n",
    "                                   '_neurons_'+ str(params['nneurons'])+\n",
    "                                   '_nin_'+ str(params['noise_x'])+\n",
    "                                   '_nout_'+ str(params['noise_r'])+\n",
    "                                   '_bsze_'+ str(params['batchsize'])+\n",
    "                                   '_epochs_'+ str(params['epochs'])+\n",
    "                                   '_lrate_'+ str(params['learning_rate'])+\n",
    "                                   '_lambda_'+ str(params['lambd'])+\n",
    "                                   '_lnorm_'+ str(params['lambda_norm'])+'/')\n",
    "\n",
    "        return(params)\n",
    "        \n",
    "    def make_dirs(self):\n",
    "        if not os.path.exists(self.params['savefolder']):\n",
    "            os.makedirs(self.params['savefolder'])\n",
    "        else:\n",
    "            filelist = [f for f in os.listdir(self.params['savefolder'])]\n",
    "            for f in filelist:\n",
    "                os.remove(self.params['savefolder']+f)\n",
    "        \n",
    "    def make_graph(self):\n",
    "    \n",
    "        print('Compressing by',self.params['compression'],'for a total of',self.params['nneurons'],'neurons')\n",
    "\n",
    "        #setup our graph\n",
    "        #tf.reset_default_graph()\n",
    "        mygraph = tf.Graph()\n",
    "        with mygraph.as_default():\n",
    "\n",
    "            #input images\n",
    "            with tf.name_scope('input'):\n",
    "                self.x = tf.placeholder(tf.float32, shape=[self.params[\"batchsize\"], \n",
    "                                                           self.params[\"imxlen\"]*self.params[\"imylen\"]])\n",
    "\n",
    "            #activation function type\n",
    "            with tf.name_scope('nonliearities'):\n",
    "                self.nonlin1 = self.params['nonlin1']\n",
    "                self.nonlin2  = self.params['nonlin2']\n",
    "\n",
    "            #noises\n",
    "            with tf.name_scope('noises'):\n",
    "                self.noisexsigma = self.params['noise_x']\n",
    "                self.noisersigma = self.params['noise_r']\n",
    "\n",
    "            #function to add noise\n",
    "            with tf.name_scope(\"add_noise\"):\n",
    "                def add_noise(input_layer, std):\n",
    "                    noise = tf.random_normal(shape=tf.shape(input_layer), mean=0.0, stddev=std, dtype=tf.float32) \n",
    "                    return tf.add(input_layer,noise)\n",
    "\n",
    "            #weights\n",
    "            with tf.variable_scope(\"weights\"):\n",
    "\n",
    "                #per Salimans et al 2016 - Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks parameterize weights as w = g/||v||*v. Now ||w|| = g and we can set g to 1 to enfoce this constraint, and learn the direction of the weights v, while maintaining magnitude of norm 1.\n",
    "                \n",
    "                weights_kernel = tf.random_normal([self.params['imxlen']*self.params['imylen'],\n",
    "                                                         self.params['nneurons']],\n",
    "                                                        dtype=tf.float32,stddev=1)\n",
    "                \n",
    "                self.vin = tf.get_variable('v_in',initializer=weights_kernel)\n",
    "                self.vout = tf.get_variable('v_out',initializer=tf.transpose(weights_kernel))\n",
    "\n",
    "                self.win = self.vin/tf.norm(self.vin,ord='euclidean')\n",
    "                self.wout = self.vout/tf.norm(self.vout,ord='euclidean')               \n",
    "\n",
    "            #bias\n",
    "            with tf.variable_scope(\"in_bias\"):\n",
    "                self.inbias = tf.Variable(tf.random_normal([self.params['nneurons']],\n",
    "                                                         dtype=tf.float32,\n",
    "                                                         stddev=1))\n",
    "            #with tf.variable_scope(\"out_bias\"):\n",
    "            #    self.outbias = tf.Variable(tf.random_normal([self.params['imxlen']*self.params['imylen']],\n",
    "            #                                             dtype=tf.float32,\n",
    "            #                                             stddev=1))\n",
    "\n",
    "            #lambda\n",
    "            with tf.name_scope('lambda'):\n",
    "                self.lambd = self.params['lambd']\n",
    "\n",
    "            #learning_rate\n",
    "            with tf.name_scope('learning_rate'):\n",
    "                self.learning_rate = self.params['learning_rate']\n",
    "\n",
    "            #nonlienarities\n",
    "            with tf.name_scope(\"nonlienarities\"):\n",
    "                #define nonlinearities\n",
    "                def tanh_fun(bias,arg):\n",
    "                    return tf.nn.tanh(tf.add(arg,bias)) \n",
    "                def sigmoid_fun(bias,arg):\n",
    "                    return tf.nn.sigmoid(tf.add(arg,bias)) \n",
    "                def relu_fun(bias,arg):\n",
    "                    return tf.nn.relu(tf.add(arg,bias)) \n",
    "                def no_fun(bias,arg):\n",
    "                    return arg\n",
    "\n",
    "            #with tf.name_scope(\"weight_normalization\"):\n",
    "            #    #weight normalization\n",
    "            #    self.win = self.win/tf.reduce_mean(tf.abs(self.win))\n",
    "            #    self.wout = self.wout/tf.reduce_mean(tf.abs(self.wout))\n",
    "\n",
    "            #encoding part of model\n",
    "            with tf.name_scope(\"encoding\"):\n",
    "                #calculate input\n",
    "                linearin = tf.add(tf.matmul(add_noise(self.x,self.params['noise_x']),self.win),self.inbias) #add noise to input, and multiply by weights\n",
    "                self.yin = tf.case({tf.equal(self.nonlin1,'tanh'): (lambda: tanh_fun(self.inbias,linearin)),\n",
    "                               tf.equal(self.nonlin1,'sigmoid'): (lambda: sigmoid_fun(self.inbias,linearin)),\n",
    "                               tf.equal(self.nonlin1,'relu'): (lambda: relu_fun(self.inbias,linearin))},\n",
    "                              default=(lambda: no_fun(self.inbias,linearin)),\n",
    "                              exclusive=True)\n",
    "                self.yin_noised = add_noise(self.yin,self.params['noise_r'])\n",
    "\n",
    "\n",
    "            #output part of model\n",
    "            with tf.name_scope(\"decoding\"):\n",
    "                #calculate output (reconstruction)\n",
    "                linearout = tf.matmul(self.yin_noised,self.wout) #add noise to inner layer, and multiply by weight  transpose\n",
    "                #self.xp = tf.case({tf.equal(self.nonlin2,'tanh'): (lambda: tanh_fun(self.outbias,linearout)),\n",
    "                #                    tf.equal(self.nonlin2,'sigmoid'): (lambda: sigmoid_fun(self.outbias,linearout)),\n",
    "                #                    tf.equal(self.nonlin2,'relu'): (lambda: relu_fun(self.outbias,linearout))},\n",
    "                #                    default=(lambda: no_fun(self.outbias,linearout)),\n",
    "                #                  exclusive=True, name='output_nonlienarity')\n",
    "                \n",
    "                self.xp = linearout\n",
    "\n",
    "            #calculate cost\n",
    "            with tf.name_scope(\"cost_function\"):\n",
    "                #non-noramlized cost\n",
    "                #self.cost = tf.sqrt(tf.reduce_mean(tf.square(self.x-self.xp))) + tf.reduce_mean(tf.abs(self.yin*self.lambd))\n",
    "                normx = self.x #- tf.reduce_min(self.x,axis=0)\n",
    "                normxp = self.xp #- tf.reduce_min(self.xp, axis=0)\n",
    "                activation = tf.norm(self.yin,ord=self.params['lambda_norm'],axis=0)\n",
    "                self.cost = tf.reduce_mean(tf.norm(normx-normxp,ord=1) + (self.lambd * activation))\n",
    "                                     \n",
    "            #train our model\n",
    "            with tf.name_scope(\"training_step\"):\n",
    "                self.train_step = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
    "                #self.train_step = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(self.cost)\n",
    "\n",
    "            # create a summary for our cost, im, reconstruction, & weights\n",
    "            with tf.name_scope('cost_viz'):\n",
    "                tf.summary.scalar(\"cost\", self.cost)\n",
    "\n",
    "            with tf.name_scope('image_viz'):    \n",
    "                x_t = tf.reshape(self.x,(self.params['batchsize'],self.params['imxlen'],self.params['imylen'],1))\n",
    "                tf.summary.image(\"image\", x_t, max_outputs=self.params[\"batchsize\"])\n",
    "\n",
    "            with tf.name_scope('recon_viz'):\n",
    "                xp_t = tf.reshape(self.xp,(self.params['batchsize'],self.params['imxlen'],self.params['imylen'],1))\n",
    "                tf.summary.image(\"recon\", xp_t,max_outputs=self.params[\"batchsize\"])\n",
    "\n",
    "            with tf.name_scope('inweights_viz'):    \n",
    "                inwin_t = tf.reshape(tf.transpose(self.win),\n",
    "                                   (self.params['nneurons'],\n",
    "                                    self.params['imxlen'],\n",
    "                                    self.params['imylen'],1))\n",
    "                tf.summary.image(\"inweights\", inwin_t, max_outputs=self.params['nneurons'])\n",
    "                \n",
    "            with tf.name_scope('outweights_viz'):    \n",
    "                outwin_t = tf.reshape(self.win,\n",
    "                                   (self.params['nneurons'],\n",
    "                                    self.params['imxlen'],\n",
    "                                    self.params['imylen'],1))\n",
    "                tf.summary.image(\"outweights\", outwin_t, max_outputs=self.params['nneurons'])\n",
    "\n",
    "            # merge all summaries into a single \"operation\" which we can execute in a session \n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "        return(mygraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#make session and train model\n",
    "def train_model(aec):\n",
    "    #with tf.device(\"/gpu:0\"):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True #don't allocate the entire GPU's memory\n",
    "    config.log_device_placement=True #tell me where devices are placed\n",
    "    with tf.Session(graph = aec.graph, config=config) as sess:\n",
    "\n",
    "        #initialize vars\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        #summary writer for tensorboard\n",
    "        writer = tf.summary.FileWriter(aec.params['savefolder'],\n",
    "                                       graph=tf.get_default_graph())\n",
    "\n",
    "        #save evolution of system over training\n",
    "        cost_evolution = []\n",
    "        wmean_evolution = []\n",
    "\n",
    "        inweights_evolution = []\n",
    "        outweights_evolution = []\n",
    "\n",
    "        images = []\n",
    "        recons = []\n",
    "        print('{} hidden neurons, noise_in at {}, noise_out at {}, lambda at {}'.format(aec.params['nneurons'],\n",
    "                                                                                        aec.params['noise_x'],\n",
    "                                                                                        aec.params['noise_r'],\n",
    "                                                                                        aec.params['lambd']))\n",
    "\n",
    "        print('Training {} iterations in {} epochs... '.format(aec.params['iterations'],\n",
    "                                                               aec.params['epochs']))\n",
    "        for epoch in range(aec.params['epochs']):\n",
    "            #print('Epoch {}: '.format(epoch+1))\n",
    "            np.random.shuffle(vhimgs.images)\n",
    "            for ii in range(aec.params['iterations']):\n",
    "\n",
    "                #reshape our images for feeding to dict\n",
    "                image = np.reshape(vhimgs.images[ii*aec.params['batchsize']:(1+ii)*aec.params['batchsize'],:,:],\n",
    "                                   (aec.params['batchsize'],\n",
    "                                    aec.params['imxlen']*aec.params['imylen'])).astype(np.float32)\n",
    "\n",
    "                #setup params to send to dictionary\n",
    "                feeddict = {aec.x: image}\n",
    "\n",
    "                #run our session\n",
    "                sess.run(aec.train_step, feed_dict=feeddict)\n",
    "\n",
    "                #save evolution of params\n",
    "                objcost, inws = sess.run([aec.cost, aec.win], feed_dict=feeddict)\n",
    "                cost_evolution.append(objcost)\n",
    "                wmean_evolution.append(np.mean(np.abs(inws)))\n",
    "\n",
    "                #print(np.linalg.norm(inws, ord='fro'))\n",
    "\n",
    "                \n",
    "                #save detailed parameters 10 times over the total evolution\n",
    "                if(ii%(int((aec.params['iterations']*aec.params['epochs'])/10))==0):\n",
    "                    print(str(ii)+', ',end=\"\")\n",
    "                    #dump our params\n",
    "                    win, wout, img, recon = sess.run([aec.win, aec.wout, aec.x, aec.xp], feed_dict=feeddict)\n",
    "                    #save our weights, image, and reconstruction\n",
    "                    inweights_evolution.append(win)\n",
    "                    outweights_evolution.append(wout)\n",
    "                    imshape = [aec.params['batchsize'],\n",
    "                               aec.params['imxlen'],\n",
    "                               aec.params['imylen']]\n",
    "            \n",
    "\n",
    "                    images.append(np.reshape(img, imshape))\n",
    "                    recons.append(np.reshape(recon, imshape))\n",
    "\n",
    "        #summarize final params\n",
    "        summary, objcost, inws, outws = sess.run([aec.summary_op, aec.cost, aec.win, aec.wout], feed_dict=feeddict)\n",
    "        cost_evolution.append(objcost)\n",
    "        wmean_evolution.append(np.mean(inws))\n",
    "        final_inweights = aec.win\n",
    "        final_outweights = aec.wout\n",
    "        writer.add_summary(summary,ii)\n",
    "        writer.close()\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "        return(cost_evolution,\n",
    "               wmean_evolution,\n",
    "               inweights_evolution,\n",
    "               outweights_evolution,\n",
    "               images,\n",
    "               recons,\n",
    "               final_inweights,\n",
    "               final_outweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set parameters for parameter sweep\n",
    "params = {} #make a dictionary\n",
    "\n",
    "#parameters constant for all\n",
    "params[\"patchsize\"] = 16\n",
    "#load in our images\n",
    "try:\n",
    "    vhimgs\n",
    "except NameError:\n",
    "    vhimgs, nimages = imr.check_n_load_ims(params['patchsize'])\n",
    "params[\"nimages\"] = nimages\n",
    "params[\"imxlen\"] = params[\"patchsize\"]\n",
    "params[\"imylen\"] = params[\"patchsize\"]\n",
    "\n",
    "#params for sweeping\n",
    "sweep_neurons = [100]\n",
    "sweep_nonlin1 = ['relu']\n",
    "sweep_nonlin2 = ['lienar']\n",
    "sweep_lambdas = [0]\n",
    "sweep_lambda_norms = [2]\n",
    "bsis = [10]\n",
    "sweep_batch_its = [[bsz,np.int(params['nimages']/bsz)] for bsz in bsis]\n",
    "sweep_epochs = [1]\n",
    "sweep_learning_rates = [0.0001] #leave this. it's good.\n",
    "sweep_noise_xs_rs = [[0,0]]\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing by 2.56 for a total of 100 neurons\n",
      "100 hidden neurons, noise_in at 0, noise_out at 0, lambda at 0\n",
      "Training 468582 iterations in 1 epochs... \n",
      "1.0\n",
      "0, 1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5806d78a3222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                                      \u001b[0mrecons\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                      \u001b[0mfinal_inweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                                      final_outweights] = train_model(aec)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                     \u001b[0;31m#save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d8ae00546f30>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(aec)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m#run our session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeeddict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m#save evolution of params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vasha/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vasha/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vasha/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/vasha/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vasha/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for neurons in sweep_neurons:\n",
    "    params['nneurons'] = neurons\n",
    "    for nonlin1 in sweep_nonlin1:\n",
    "        params['nonlin1'] = nonlin1\n",
    "        for nonlin2 in sweep_nonlin2:\n",
    "            params['nonlin2'] = nonlin2\n",
    "            for lambd in sweep_lambdas:\n",
    "                params['lambd'] = lambd\n",
    "                for lambdn in sweep_lambda_norms:\n",
    "                    params['lambda_norm'] = lambdn\n",
    "                    for batchsize, iterations in sweep_batch_its:\n",
    "                        params['batchsize'] = batchsize\n",
    "                        params['iterations'] = iterations\n",
    "                        for epos in sweep_epochs:\n",
    "                            params['epochs'] = epos\n",
    "                            for lr in sweep_learning_rates:\n",
    "                                params['learning_rate'] = lr\n",
    "                                for xs,rs in sweep_noise_xs_rs:\n",
    "                                    params['noise_x'] = xs\n",
    "                                    params['noise_r'] = rs\n",
    "\n",
    "                                    #make our model\n",
    "                                    aec = aec_model(params)\n",
    "                                    #train it'\n",
    "                                    [cost_evolution,\n",
    "                                     wmean_evolution,\n",
    "                                     inweights_evolution,\n",
    "                                     outweights_evolution,\n",
    "                                     images,\n",
    "                                     recons,\n",
    "                                     final_inweights,\n",
    "                                     final_outweights] = train_model(aec)\n",
    "\n",
    "                                    #save model \n",
    "                                    plu.save_plots(aec,\n",
    "                                                   cost_evolution,\n",
    "                                                   wmean_evolution,\n",
    "                                                   inweights_evolution,\n",
    "                                                   outweights_evolution,\n",
    "                                                   images,\n",
    "                                                   recons,\n",
    "                                                   final_inweights,\n",
    "                                                   final_outweights)\n",
    "print(\"*** Parameter Sweep Finished! ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True #don't allocate the entire GPU's memory\n",
    "config.log_device_placement=True\n",
    "sess = tf.Session(config=config)\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inweights_evolution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c8819913c445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m inweights_evolution_r = np.rollaxis(np.reshape(inweights_evolution,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                  (len(inweights_evolution),\n\u001b[1;32m      3\u001b[0m                                                   \u001b[0maec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imxlen'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                   \u001b[0maec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imylen'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     aec.params['nneurons'])),3,1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inweights_evolution' is not defined"
     ]
    }
   ],
   "source": [
    "inweights_evolution_r = np.rollaxis(np.reshape(inweights_evolution,\n",
    "                                                 (len(inweights_evolution),\n",
    "                                                  aec.params['imxlen'],\n",
    "                                                  aec.params['imylen'],\n",
    "                                                    aec.params['nneurons'])),3,1)\n",
    "\n",
    "\n",
    "plu.display_data_tiled(inweights_evolution_r[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53176106924\n",
      "1.82435968332\n",
      "1.0\n",
      "1.1910210541\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAEAAALJCAYAAADF6Dr7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGAEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3808aa39e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = np.random.randn(100)*2\n",
    "#plt.hist(w)\n",
    "\n",
    "w2 = w/np.mean(np.abs(w))\n",
    "print(np.mean(np.abs(w)))\n",
    "print(np.std(w))\n",
    "\n",
    "plt.hist(w2)\n",
    "print(np.mean(np.abs(w2)))\n",
    "print(np.std(w2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
